#!/bin/bash
# ca_lnhpd è³‡æ–™æ›´æ–°è…³æœ¬ - æ‰¹æ¬¡è™•ç†ç‰ˆæœ¬
# è·è²¬ï¼šQdrant æ›´æ–° + REVIEW_NEEDED æª¢æŸ¥

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../../../.." && pwd)"

source "$PROJECT_ROOT/lib/args.sh"
source "$PROJECT_ROOT/lib/core.sh"
source "$PROJECT_ROOT/lib/qdrant.sh"
source "$PROJECT_ROOT/lib/chatgpt.sh"

require_cmd jq

LAYER_NAME="ca_lnhpd"
DOCS_DIR="$PROJECT_ROOT/docs/Extractor/$LAYER_NAME"
BATCH_SIZE=200
LAST_UPDATE_FILE="$DOCS_DIR/.last_qdrant_update"

# === è§£æåƒæ•¸ ===
parse_args "$@"
arg_optional "full" FULL_MODE "false"

# ç¢ºä¿åˆ†é¡å­ç›®éŒ„å­˜åœ¨
for category in vitamins_minerals botanicals protein_amino probiotics omega_fatty_acids specialty sports_fitness other; do
  mkdir -p "$DOCS_DIR/$category"
done

########################################
# Helper: æ‰¹æ¬¡ ID è½‰ UUID
########################################
# è¼¸å…¥ï¼šnewline-separated IDs
# è¼¸å‡ºï¼šnewline-separated UUIDs
_batch_ids_to_uuids() {
  python3 -c '
import sys
import uuid

for line in sys.stdin:
    point_id = line.strip()
    if not point_id:
        continue
    # ç”Ÿæˆç¢ºå®šæ€§ UUID v5
    point_uuid = str(uuid.uuid5(uuid.NAMESPACE_URL, point_id))
    print(point_uuid)
'
}

# === å–å¾—è¦è™•ç†çš„ .md æª”æ¡ˆ ===
MD_FILES=()
POSITIONAL_ARGS=("${POSITIONAL_ARGS[@]:-}")
if [[ ${#POSITIONAL_ARGS[@]} -gt 0 ]]; then
  MD_FILES=("${POSITIONAL_ARGS[@]}")
elif [[ "$FULL_MODE" != "false" ]] || [[ ! -f "$LAST_UPDATE_FILE" ]]; then
  echo "ğŸ“‚ å…¨é‡æ¨¡å¼ï¼šæƒææ‰€æœ‰ .md æª”æ¡ˆ"
  while IFS= read -r -d '' f; do
    MD_FILES+=("$f")
  done < <(find "$DOCS_DIR" -name "*.md" -not -path "*/raw/*" -type f -print0 2>/dev/null)
else
  echo "ğŸ“‚ å¢é‡æ¨¡å¼ï¼šåªè™•ç†æ–°å¢/ä¿®æ”¹çš„æª”æ¡ˆ"
  while IFS= read -r -d '' f; do
    MD_FILES+=("$f")
  done < <(find "$DOCS_DIR" -name "*.md" -not -path "*/raw/*" -type f -newer "$LAST_UPDATE_FILE" -print0 2>/dev/null)
fi

if [[ ${#MD_FILES[@]} -eq 0 ]]; then
  echo "â„¹ï¸  æ²’æœ‰æ‰¾åˆ° .md æª”æ¡ˆéœ€è¦è™•ç†"
  exit 0
fi

echo "ğŸ“‹ å¾…è™•ç†ï¼š${#MD_FILES[@]} å€‹ .md æª”æ¡ˆ"

# === Qdrant æ›´æ–° ===
QDRANT_OK=false
if [[ -n "${QDRANT_URL:-}" ]]; then
  if qdrant_init_env 2>/dev/null; then
    QDRANT_OK=true
    echo "âœ… Qdrant é€£ç·šå°±ç·’"
    COLLECTION="${QDRANT_COLLECTION:-supplement-product}"
    DIMENSION="${EMBEDDING_DIMENSION:-1536}"
    qdrant_create_collection "$COLLECTION" "$DIMENSION" 2>/dev/null || true
  else
    echo "âš ï¸  Qdrant é€£ç·šå¤±æ•—ï¼Œè·³éå‘é‡æ›´æ–°" >&2
  fi
fi

EMBED_OK=false
if [[ -n "${OPENAI_API_KEY:-}" ]]; then
  if chatgpt_init_env 2>/dev/null; then
    EMBED_OK=true
    echo "âœ… OpenAI embedding å°±ç·’"
  fi
fi

# === è™•ç†è¨ˆæ•¸å™¨ ===
PROCESSED=0
SKIPPED=0
ERRORS=0

# === æ‰¹æ¬¡è™•ç†ä¸»å¾ªç’° ===
total_files="${#MD_FILES[@]}"
batch_start=0

while [[ $batch_start -lt $total_files ]]; do
  batch_end=$((batch_start + BATCH_SIZE))
  if [[ $batch_end -gt $total_files ]]; then
    batch_end=$total_files
  fi

  echo ""
  echo "è™•ç†æ‰¹æ¬¡ï¼š$((batch_start + 1))-${batch_end}/${total_files}"

  # === Phase 1: æ”¶é›† ID èˆ‡æª”æ¡ˆè·¯å¾‘æ˜ å°„ ===
  declare -a point_ids=()      # æ‰€æœ‰ POINT_ID (ca_lnhpd-{SOURCE_ID})
  declare -a batch_files=()    # æœ¬æ‰¹æ¬¡çš„æª”æ¡ˆ

  for ((i=batch_start; i<batch_end; i++)); do
    md_file="${MD_FILES[$i]}"

    if [[ ! -f "$md_file" ]]; then
      ((ERRORS++)) || true
      continue
    fi

    batch_files+=("$md_file")

    # æå– source_id
    SOURCE_ID="$(sed -n 's/^source_id: *"\{0,1\}\([^"]*\)"\{0,1\} *$/\1/p' "$md_file" | head -1)"
    if [[ -z "$SOURCE_ID" ]]; then
      echo "âš ï¸  ç„¡æ³•æå– source_idï¼š$md_file" >&2
      ((ERRORS++)) || true
      continue
    fi

    POINT_ID="ca_lnhpd-${SOURCE_ID}"
    point_ids+=("$POINT_ID")
  done

  if [[ ${#point_ids[@]} -eq 0 ]]; then
    echo "âš ï¸  æœ¬æ‰¹æ¬¡ç„¡æœ‰æ•ˆæª”æ¡ˆï¼Œè·³é"
    batch_start=$batch_end
    continue
  fi

  # æ‰¹æ¬¡è½‰æ› ID åˆ° UUID
  declare -a point_uuids=()
  while IFS= read -r uuid; do
    [[ -z "$uuid" ]] && continue
    point_uuids+=("$uuid")
  done < <(printf '%s\n' "${point_ids[@]}" | _batch_ids_to_uuids)

  if [[ ${#point_uuids[@]} -ne ${#point_ids[@]} ]]; then
    echo "âŒ UUID è½‰æ›å¤±æ•—ï¼šæœŸæœ› ${#point_ids[@]} å€‹ï¼Œå¾—åˆ° ${#point_uuids[@]} å€‹" >&2
    ((ERRORS+=${#batch_files[@]})) || true
    batch_start=$batch_end
    continue
  fi

  # === Phase 2: æ‰¹æ¬¡æŸ¥é‡ (å¦‚æœ Qdrant å’Œ Embed éƒ½å°±ç·’) ===
  declare -a indices_to_process=()

  if [[ "$QDRANT_OK" == "true" && "$EMBED_OK" == "true" ]]; then
    # æ§‹å»º IDS_JSON
    IDS_JSON="$(printf '%s\n' "${point_uuids[@]}" | jq -Rsc 'split("\n") | map(select(length > 0))')"

    # æ‰¹æ¬¡æŸ¥è©¢å·²å­˜åœ¨çš„ IDs
    EXISTING_IDS="$(qdrant_get_existing_ids "$COLLECTION" "$IDS_JSON" 2>/dev/null)" || {
      echo "âš ï¸  æ‰¹æ¬¡æŸ¥è©¢å¤±æ•—ï¼Œå‡è¨­æ‰€æœ‰æª”æ¡ˆéƒ½éœ€è™•ç†" >&2
      EXISTING_IDS="[]"
    }

    # éæ¿¾æ‰å·²å­˜åœ¨çš„æª”æ¡ˆ
    for ((i=0; i<${#point_uuids[@]}; i++)); do
      uuid="${point_uuids[$i]}"

      if echo "$EXISTING_IDS" | jq -e --arg uuid "$uuid" '. | index($uuid)' >/dev/null 2>&1; then
        ((SKIPPED++)) || true
      else
        indices_to_process+=("$i")
      fi
    done
  else
    # æ²’æœ‰ Qdrant/Embedï¼Œç›´æ¥æ¨™è¨˜ç‚ºè™•ç†ï¼ˆè¨ˆæ•¸ç”¨ï¼‰
    for ((i=0; i<${#batch_files[@]}; i++)); do
      indices_to_process+=("$i")
    done
    ((PROCESSED+=${#indices_to_process[@]})) || true
    batch_start=$batch_end
    continue
  fi

  if [[ ${#indices_to_process[@]} -eq 0 ]]; then
    echo "âœ“ æœ¬æ‰¹æ¬¡æ‰€æœ‰æª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³é"
    batch_start=$batch_end
    continue
  fi

  echo "éœ€è™•ç†ï¼š${#indices_to_process[@]} å€‹æª”æ¡ˆ"

  # === Phase 3: æå–æ–‡æœ¬èˆ‡ metadata ===
  tmp_texts_file="$(mktemp)"
  declare -a process_metadata=()  # å„²å­˜ metadata JSON strings

  jq -n '[]' > "$tmp_texts_file"  # åˆå§‹åŒ–ç‚ºç©º array

  for idx in "${indices_to_process[@]}"; do
    file="${batch_files[$idx]}"
    # æå– frontmatter æ¬„ä½
    SOURCE_ID="$(sed -n 's/^source_id: *"\{0,1\}\([^"]*\)"\{0,1\} *$/\1/p' "$file" | head -1)"
    PRODUCT_NAME="$(sed -n 's/^product_name: *"\{0,1\}\([^"]*\)"\{0,1\} *$/\1/p' "$file" | head -1)"
    BRAND="$(sed -n 's/^brand: *"\{0,1\}\([^"]*\)"\{0,1\} *$/\1/p' "$file" | head -1)"
    CATEGORY="$(sed -n 's/^category: *"\{0,1\}\([^"]*\)"\{0,1\} *$/\1/p' "$file" | head -1)"
    PRODUCT_FORM="$(sed -n 's/^product_form: *"\{0,1\}\([^"]*\)"\{0,1\} *$/\1/p' "$file" | head -1)"
    SOURCE_URL="$(sed -n 's/^source_url: *"\{0,1\}\([^"]*\)"\{0,1\} *$/\1/p' "$file" | head -1)"
    DATE_ENTERED="$(sed -n 's/^date_entered: *"\{0,1\}\([^"]*\)"\{0,1\} *$/\1/p' "$file" | head -1)"
    FETCHED_AT="$(sed -n 's/^fetched_at: *"\{0,1\}\([^"]*\)"\{0,1\} *$/\1/p' "$file" | head -1)"

    # æå– body text (è·³é frontmatterï¼Œå–å‰ 500 è¡Œ)
    BODY_TEXT="$(sed -n '/^---$/,/^---$/!p' "$file" | head -500)"

    # å°‡ body text åŠ å…¥ texts array
    jq --arg text "$BODY_TEXT" '. += [$text]' "$tmp_texts_file" > "${tmp_texts_file}.tmp"
    mv "${tmp_texts_file}.tmp" "$tmp_texts_file"

    # å„²å­˜ metadata (ä½¿ç”¨ -c ç”¢ç”Ÿå–®è¡Œ JSON)
    METADATA="$(jq -nc \
      --arg source_id "$SOURCE_ID" \
      --arg product_name "$PRODUCT_NAME" \
      --arg brand "$BRAND" \
      --arg category "$CATEGORY" \
      --arg product_form "$PRODUCT_FORM" \
      --arg source_url "$SOURCE_URL" \
      --arg date_entered "$DATE_ENTERED" \
      --arg fetched_at "$FETCHED_AT" \
      '{
        source_id: $source_id,
        source_layer: "ca_lnhpd",
        source_url: $source_url,
        market: "ca",
        product_name: $product_name,
        brand: $brand,
        manufacturer: $brand,
        category: $category,
        product_form: $product_form,
        date_entered: $date_entered,
        fetched_at: $fetched_at
      }'
    )"
    process_metadata+=("$METADATA")
  done

  # === Phase 4: æ‰¹æ¬¡ embedding ===
  echo "ç”¢ç”Ÿ embeddings..."
  tmp_embeddings_file="$(mktemp)"

  if ! chatgpt_embed_batch "$tmp_texts_file" > "$tmp_embeddings_file" 2>/dev/null; then
    echo "âŒ æ‰¹æ¬¡ embedding å¤±æ•—ï¼Œæœ¬æ‰¹æ¬¡è¨ˆå…¥éŒ¯èª¤" >&2
    ((ERRORS+=${#indices_to_process[@]})) || true
    rm -f "$tmp_texts_file" "$tmp_embeddings_file"
    batch_start=$batch_end
    continue
  fi

  # === Phase 5: æ‰¹æ¬¡ upsert ===
  echo "æ‰¹æ¬¡å¯«å…¥ Qdrant..."

  # æ§‹å»º POINTS_JSONï¼ˆä½¿ç”¨ Phase 1 å·²è¨ˆç®—çš„ UUIDï¼‰
  POINTS_JSON="$(
    paste \
      <(for idx in "${indices_to_process[@]}"; do echo "${point_uuids[$idx]}"; done) \
      <(printf '%s\n' "${process_metadata[@]}") \
      <(jq -c '.[]' "$tmp_embeddings_file") \
    | while IFS=$'\t' read -r uuid metadata_json embedding_json; do
        jq -n \
          --arg id "$uuid" \
          --argjson vector "$embedding_json" \
          --argjson payload "$metadata_json" \
          '{
            id: $id,
            vector: $vector,
            payload: $payload
          }'
      done | jq -sc '.'
  )"

  if qdrant_upsert_points_batch "$COLLECTION" "$POINTS_JSON" 2>/dev/null; then
    ((PROCESSED+=${#indices_to_process[@]})) || true
    echo "âœ“ æˆåŠŸå¯«å…¥ ${#indices_to_process[@]} å€‹ points"
  else
    echo "âŒ æ‰¹æ¬¡ upsert å¤±æ•—" >&2
    ((ERRORS+=${#indices_to_process[@]})) || true
  fi

  # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
  rm -f "$tmp_texts_file" "$tmp_embeddings_file"

  batch_start=$batch_end
done

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ“Š Update çµæœï¼š"
echo "   å·²è™•ç†ï¼š${PROCESSED}"
echo "   å·²è·³éï¼ˆå·²å­˜åœ¨ï¼‰ï¼š${SKIPPED}"
echo "   éŒ¯èª¤ï¼š${ERRORS}"

# === REVIEW_NEEDED æª¢æŸ¥ ===
REVIEW_FILES=""
while IFS= read -r -d '' f; do
  if grep -q "\[REVIEW_NEEDED\]" "$f" 2>/dev/null; then
    REVIEW_FILES+="  - $f\n"
  fi
done < <(find "$DOCS_DIR" -name "*.md" -not -path "*/raw/*" -type f -print0 2>/dev/null)

if [[ -n "$REVIEW_FILES" ]]; then
  echo ""
  echo "âš ï¸  éœ€è¦å¯©æ ¸ï¼š"
  echo -e "$REVIEW_FILES"
fi

# === æ›´æ–°æ™‚é–“æˆ³ï¼ˆä¾›å¢é‡æ›´æ–°ä½¿ç”¨ï¼‰===
if [[ "$QDRANT_OK" == "true" && "$EMBED_OK" == "true" && $ERRORS -eq 0 ]]; then
  touch "$LAST_UPDATE_FILE"
  echo "ğŸ“Œ å·²æ›´æ–°æ™‚é–“æˆ³ï¼š$LAST_UPDATE_FILE"
fi

echo ""
echo "âœ… Update completed: $LAYER_NAME"
