#!/usr/bin/env python3
"""
AI ç”¢ç”Ÿä¸»é¡Œé¦–é å’Œé¸è³¼æŒ‡å—

çµåˆç”¢å“è³‡æ–™èˆ‡ç¶²è·¯æœå°‹ï¼Œç”¨ AI è‡ªå‹•ç”¢ç”Ÿ index.md å’Œ guide.md çš„å…§å®¹ã€‚

ç”¨æ³•ï¼š
  python3 scripts/generate_topic_content.py --topic exosomes
  python3 scripts/generate_topic_content.py --all
  python3 scripts/generate_topic_content.py --topic fish-oil --skip-web

æµç¨‹ï¼š
1. è®€å– topics/{topic_id}.yaml å–å¾—ä¸»é¡Œå®šç¾©
2. æƒæç”¢å“è³‡æ–™ï¼Œç¯©é¸åŒ¹é…çš„ç”¢å“
3. å½™æ•´ç”¢å“çš„ health_claim, ingredients, form ç­‰æ¬„ä½
4. åŸ·è¡Œç¶²è·¯æœå°‹ï¼ˆå¯é¸ï¼‰
5. æ•´åˆæ‰€æœ‰è³‡æ–™ï¼Œå‘¼å« Claude API ç”¢ç”Ÿå…§å®¹
6. å¯«å…¥ docs/reports/{topic_id}/index.md å’Œ guide.md
"""

import argparse
import json
import os
import re
import yaml
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import Optional

try:
    import anthropic
    HAS_ANTHROPIC = True
except ImportError:
    HAS_ANTHROPIC = False

try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    HAS_REQUESTS = False


# è·¯å¾‘é…ç½®
PROJECT_ROOT = Path(__file__).parent.parent
TOPICS_DIR = PROJECT_ROOT / "core" / "Narrator" / "Modes" / "topic_tracking" / "topics"
EXTRACTOR_DIR = PROJECT_ROOT / "docs" / "Extractor"
REPORTS_DIR = PROJECT_ROOT / "docs" / "reports"

# Layer å°æ‡‰å¸‚å ´
LAYER_MARKET = {
    "us_dsld": {"name": "ç¾åœ‹", "flag": "ğŸ‡ºğŸ‡¸", "code": "US"},
    "ca_lnhpd": {"name": "åŠ æ‹¿å¤§", "flag": "ğŸ‡¨ğŸ‡¦", "code": "CA"},
    "kr_hff": {"name": "éŸ“åœ‹", "flag": "ğŸ‡°ğŸ‡·", "code": "KR"},
    "jp_fnfc": {"name": "æ—¥æœ¬ FNFC", "flag": "ğŸ‡¯ğŸ‡µ", "code": "JP"},
    "jp_foshu": {"name": "æ—¥æœ¬ FOSHU", "flag": "ğŸ‡¯ğŸ‡µ", "code": "JP"},
    "tw_hf": {"name": "å°ç£", "flag": "ğŸ‡¹ğŸ‡¼", "code": "TW"},
}

# ç¶²è·¯æœå°‹æŸ¥è©¢æ¨¡æ¿
SEARCH_QUERIES = {
    "science": [
        "{topic_en} mechanism of action",
        "{topic_en} clinical study benefits",
        "{topic_en} research 2024 2025",
    ],
    "safety": [
        "{topic_zh} å‰¯ä½œç”¨ æ³¨æ„äº‹é …",
        "{topic_en} side effects contraindications",
    ],
    "consumer": [
        "{topic_zh} æ¨è–¦ è©•åƒ¹",
        "{topic_zh} PTT å¿ƒå¾—",
        "{topic_en} review comparison",
    ],
    "market": [
        "{topic_en} market size trend",
        "{topic_zh} å¸‚å ´è¦æ¨¡ è¶¨å‹¢",
    ],
}


def load_topic(topic_id: str) -> Optional[dict]:
    """è¼‰å…¥ä¸»é¡Œå®šç¾©"""
    yaml_path = TOPICS_DIR / f"{topic_id}.yaml"
    if not yaml_path.exists():
        return None
    with open(yaml_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def load_all_topics() -> list[dict]:
    """è¼‰å…¥æ‰€æœ‰ä¸»é¡Œå®šç¾©"""
    topics = []
    for yaml_file in TOPICS_DIR.glob("*.yaml"):
        with open(yaml_file, "r", encoding="utf-8") as f:
            topic = yaml.safe_load(f)
            topics.append(topic)
    return topics


def parse_product_file(file_path: Path) -> Optional[dict]:
    """è§£æç”¢å“ Markdown æª”æ¡ˆ"""
    content = file_path.read_text(encoding="utf-8")

    # è·³é REVIEW_NEEDED ç”¢å“
    if "[REVIEW_NEEDED]" in content:
        return None

    product = {
        "file_path": str(file_path),
        "name": "",
        "brand": "",
        "manufacturer": "",
        "ingredients": [],
        "health_claim": "",
        "form": "",
        "layer": file_path.parent.parent.name,
        "category": file_path.parent.name,
    }

    # è§£æ frontmatter
    if content.startswith("---"):
        parts = content.split("---", 2)
        if len(parts) >= 3:
            try:
                fm = yaml.safe_load(parts[1])
                if fm:
                    product["name"] = fm.get("product_name", "")
                    product["brand"] = fm.get("brand", "")
                    product["manufacturer"] = fm.get("manufacturer", "")
                    product["form"] = fm.get("product_form", "")
                    product["health_claim"] = fm.get("health_claim", "")
            except yaml.YAMLError:
                pass

    # æå–æˆåˆ†
    ingredient_patterns = [
        r"## æˆåˆ†\s*\n([\s\S]*?)(?=\n##|\Z)",
        r"## æ©Ÿèƒ½æ€§æˆåˆ†\s*\n([\s\S]*?)(?=\n##|\Z)",
        r"## æ©Ÿèƒ½æ€§é–¢ä¸æˆåˆ†\s*\n([\s\S]*?)(?=\n##|\Z)",
        r"## Ingredients\s*\n([\s\S]*?)(?=\n##|\Z)",
    ]

    for pattern in ingredient_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            ingredients_text = match.group(1)
            for line in ingredients_text.split("\n"):
                line = line.strip()
                if line.startswith("- "):
                    product["ingredients"].append(line[2:].strip())
                elif line and not line.startswith("#"):
                    product["ingredients"].append(line)

    # æå–å¥åº·è²æ˜ï¼ˆå¦‚æœ frontmatter æ²’æœ‰ï¼‰
    if not product["health_claim"]:
        claim_patterns = [
            r"## å¥åº·è²æ˜\s*\n([\s\S]*?)(?=\n##|\Z)",
            r"## Health Claim\s*\n([\s\S]*?)(?=\n##|\Z)",
            r"## å±Šå‡ºè¡¨ç¤º\s*\n([\s\S]*?)(?=\n##|\Z)",
        ]
        for pattern in claim_patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                product["health_claim"] = match.group(1).strip()[:500]
                break

    return product


def match_product(product: dict, topic: dict) -> bool:
    """æª¢æŸ¥ç”¢å“æ˜¯å¦åŒ¹é…ä¸»é¡Œé—œéµè©"""
    if not product:
        return False

    keywords = topic.get("keywords", {})
    exact_keywords = [k.lower() for k in keywords.get("exact", [])]
    fuzzy_keywords = [k.lower() for k in keywords.get("fuzzy", [])]

    # ç²¾ç¢ºåŒ¹é…æˆåˆ†
    for ingredient in product.get("ingredients", []):
        ingredient_lower = ingredient.lower()
        for keyword in exact_keywords:
            if keyword in ingredient_lower:
                return True

    # æ¨¡ç³ŠåŒ¹é…ç”¢å“åç¨±å’Œå¥åº·è²æ˜
    search_text = " ".join([
        product.get("name", ""),
        product.get("health_claim", ""),
    ]).lower()

    for keyword in exact_keywords + fuzzy_keywords:
        if keyword in search_text:
            return True

    return False


def scan_products(topic: dict, sample_limit: int = 0) -> list[dict]:
    """æƒæä¸¦ç¯©é¸ç¬¦åˆä¸»é¡Œçš„ç”¢å“

    Args:
        topic: ä¸»é¡Œå®šç¾©
        sample_limit: å–æ¨£ä¸Šé™ï¼Œ0 è¡¨ç¤ºä¸é™åˆ¶
    """
    matched_products = []
    category_filter = topic.get("category_filter", [])
    scanned = 0

    print("  ", end="", flush=True)

    for layer_dir in EXTRACTOR_DIR.iterdir():
        if not layer_dir.is_dir():
            continue
        if layer_dir.name not in LAYER_MARKET:
            continue

        for category_dir in layer_dir.iterdir():
            if not category_dir.is_dir():
                continue
            if category_dir.name == "raw":
                continue
            if category_filter and category_dir.name not in category_filter:
                continue

            for product_file in category_dir.glob("*.md"):
                scanned += 1
                if scanned % 10000 == 0:
                    print(".", end="", flush=True)

                product = parse_product_file(product_file)
                if product and match_product(product, topic):
                    matched_products.append(product)

                    # å–æ¨£é™åˆ¶
                    if sample_limit > 0 and len(matched_products) >= sample_limit:
                        print(f" (å–æ¨£ {sample_limit} ç­†)")
                        return matched_products

    print(f" (æƒæ {scanned} ç­†)")
    return matched_products


def summarize_products(products: list[dict]) -> dict:
    """å½™æ•´ç”¢å“è³‡æ–™çµ±è¨ˆ"""
    summary = {
        "count": len(products),
        "markets": defaultdict(int),
        "forms": defaultdict(int),
        "brands": defaultdict(int),
        "health_claims": [],
        "ingredients": defaultdict(int),
    }

    for product in products:
        # å¸‚å ´çµ±è¨ˆ
        layer = product.get("layer", "")
        if layer in LAYER_MARKET:
            summary["markets"][LAYER_MARKET[layer]["name"]] += 1

        # åŠ‘å‹çµ±è¨ˆ
        form = product.get("form") or "æœªçŸ¥"
        summary["forms"][form] += 1

        # å“ç‰Œçµ±è¨ˆ
        brand = product.get("brand") or product.get("manufacturer") or "æœªçŸ¥"
        summary["brands"][brand] += 1

        # å¥åº·è²æ˜æ”¶é›†
        claim = product.get("health_claim", "")
        if claim and len(claim) > 10:
            summary["health_claims"].append(claim[:200])

        # æˆåˆ†çµ±è¨ˆ
        for ingredient in product.get("ingredients", []):
            summary["ingredients"][ingredient.lower()[:50]] += 1

    # è½‰æ›ç‚ºæ’åºåˆ—è¡¨
    summary["markets"] = dict(sorted(summary["markets"].items(), key=lambda x: -x[1]))
    summary["forms"] = dict(sorted(summary["forms"].items(), key=lambda x: -x[1])[:10])
    summary["brands"] = dict(sorted(summary["brands"].items(), key=lambda x: -x[1])[:20])
    summary["ingredients"] = dict(sorted(summary["ingredients"].items(), key=lambda x: -x[1])[:30])

    # å–ä»£è¡¨æ€§å¥åº·è²æ˜
    summary["health_claims"] = summary["health_claims"][:10]

    return summary


def format_product_summary(summary: dict, topic: dict) -> str:
    """æ ¼å¼åŒ–ç”¢å“æ‘˜è¦ä¾› AI ä½¿ç”¨"""
    output = f"""## ç”¢å“è³‡æ–™æ‘˜è¦ï¼ˆä¾†è‡ªå®˜æ–¹è³‡æ–™åº«ï¼‰

- **ç”¢å“æ•¸é‡**ï¼š{summary['count']} ç­†
- **æ¶µè“‹å¸‚å ´**ï¼š{', '.join([f"{k}({v}ç­†)" for k, v in list(summary['markets'].items())[:5]])}

### å¸¸è¦‹åŠ‘å‹
{chr(10).join([f"- {k}: {v} ç­†" for k, v in list(summary['forms'].items())[:5]])}

### å¸¸è¦‹å“ç‰Œ/è£½é€ å•†
{chr(10).join([f"- {k}: {v} ç­†" for k, v in list(summary['brands'].items())[:10] if k != 'æœªçŸ¥'])}

### å¸¸è¦‹æˆåˆ†
{chr(10).join([f"- {k}: {v} æ¬¡" for k, v in list(summary['ingredients'].items())[:15]])}

### ä»£è¡¨æ€§å¥åº·è²æ˜
"""
    for i, claim in enumerate(summary["health_claims"][:5], 1):
        output += f"{i}. {claim}\n"

    return output


def generate_search_queries(topic: dict) -> dict[str, list[str]]:
    """ç”¢ç”Ÿç¶²è·¯æœå°‹æŸ¥è©¢"""
    topic_zh = topic["name"].get("zh", "")
    topic_en = topic["name"].get("en", "")

    queries = {}
    for category, templates in SEARCH_QUERIES.items():
        queries[category] = [
            t.format(topic_zh=topic_zh, topic_en=topic_en)
            for t in templates
        ]

    return queries


def format_web_results_placeholder(topic: dict) -> str:
    """ç”¢ç”Ÿç¶²è·¯æœå°‹çµæœçš„ä½”ä½ç¬¦ï¼ˆæç¤ºéœ€è¦æ‰‹å‹•æœå°‹ï¼‰"""
    queries = generate_search_queries(topic)

    output = """## ç¶²è·¯æœå°‹çµæœ

> ä»¥ä¸‹ç‚ºå»ºè­°æœå°‹çš„æŸ¥è©¢ï¼Œè«‹ä½¿ç”¨ WebSearch å·¥å…·åŸ·è¡Œæœå°‹å¾Œè£œå……ï¼š

### ç§‘å­¸ç ”ç©¶
"""
    for q in queries["science"]:
        output += f"- [ ] `{q}`\n"

    output += "\n### å®‰å…¨è³‡è¨Š\n"
    for q in queries["safety"]:
        output += f"- [ ] `{q}`\n"

    output += "\n### æ¶ˆè²»è€…è©•åƒ¹\n"
    for q in queries["consumer"]:
        output += f"- [ ] `{q}`\n"

    output += "\n### å¸‚å ´è¶¨å‹¢\n"
    for q in queries["market"]:
        output += f"- [ ] `{q}`\n"

    return output


def generate_index_prompt(topic: dict, product_summary: str, web_results: str) -> str:
    """ç”¢ç”Ÿ index.md çš„ AI prompt"""
    topic_name = topic["name"]["zh"]

    return f"""ä½ æ˜¯ä¿å¥é£Ÿå“å°ˆå®¶ã€‚æ ¹æ“šä»¥ä¸‹ {topic_name} ç›¸é—œè³‡æ–™ï¼Œ
æ’°å¯«ä¸€ä»½å®¢è§€ä¸­ç«‹çš„ä¸»é¡Œä»‹ç´¹é é¢ã€‚

{product_summary}

{web_results}

## è¼¸å‡ºæ ¼å¼

è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¾ç…§ä»¥ä¸‹çµæ§‹æ’°å¯«ã€‚æ¯å€‹æ®µè½ 150-300 å­—ï¼Œç›¡é‡å¼•ç”¨å…·é«”æ•¸æ“šï¼š

```markdown
# {topic_name}

## è¦è§£æ±ºä»€éº¼å•é¡Œï¼Ÿ

ï¼ˆçµåˆå¥åº·è²æ˜åˆ†ææ¶ˆè²»è€…çš„ä¸»è¦éœ€æ±‚ï¼Œèªªæ˜é€™é¡ç”¢å“ä¸»è¦é‡å°ä»€éº¼å•é¡Œï¼‰

## é€ æˆå•é¡Œçš„åŸå› 

ï¼ˆèªªæ˜ç‚ºä»€éº¼æœƒæœ‰é€™äº›å¥åº·å•é¡Œï¼Œå¯èƒ½çš„æˆå› ï¼‰

## å¸‚é¢è§£æ±ºæ–¹æ¡ˆåˆ†æ

ï¼ˆå®¢è§€æ¯”è¼ƒå¸‚é¢ä¸Šä¸åŒé¡å‹çš„ç”¢å“ï¼ŒåŒ…æ‹¬åŠ‘å‹ã€åŠ‘é‡ã€å“ç‰Œç‰¹é»ï¼‰

## ä½œç”¨æ©Ÿè½‰

ï¼ˆèªªæ˜ä¸»è¦æˆåˆ†å¦‚ä½•ç™¼æ®ä½œç”¨çš„ç§‘å­¸åŸç†ï¼‰

## ç™¼å±•æ­·å²èˆ‡ç¾æ³

ï¼ˆæ ¹æ“šç”¢å“çµ±è¨ˆæ•¸æ“šï¼Œåˆ†æå¸‚å ´ç™¼å±•è¶¨å‹¢ï¼‰

## åƒè€ƒæ–‡ç»

ï¼ˆåˆ—å‡ºè³‡æ–™ä¾†æºï¼‰
```

æ³¨æ„ï¼š
1. ä¿æŒå®¢è§€ä¸­ç«‹ï¼Œä¸åšç™‚æ•ˆå®£ç¨±
2. å¼•ç”¨å…·é«”çš„ç”¢å“çµ±è¨ˆæ•¸æ“š
3. æ¨™è¨»è³‡è¨Šä¾†æº
4. è‹¥è³‡æ–™ä¸è¶³ï¼Œè«‹æ¨™è¨»ã€Œå¾…è£œå……ã€
"""


def generate_guide_prompt(topic: dict, product_summary: str, web_results: str) -> str:
    """ç”¢ç”Ÿ guide.md çš„ AI prompt"""
    topic_name = topic["name"]["zh"]

    return f"""ä½ æ˜¯ä¿å¥é£Ÿå“é¸è³¼é¡§å•ã€‚æ ¹æ“šä»¥ä¸‹ {topic_name} ç›¸é—œè³‡æ–™ï¼Œ
æ’°å¯«ä¸€ä»½å¯¦ç”¨çš„é¸è³¼æŒ‡å—ã€‚

{product_summary}

{web_results}

## è¼¸å‡ºæ ¼å¼

è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¾ç…§ä»¥ä¸‹çµæ§‹æ’°å¯«ï¼š

```markdown
# {topic_name}é¸è³¼æŒ‡å—

## æ±ºç­–æ¨¹

ï¼ˆç”¨æ–‡å­—æè¿°é¸è³¼æ±ºç­–æµç¨‹ï¼Œå¹«åŠ©æ¶ˆè²»è€…æ ¹æ“šè‡ªèº«éœ€æ±‚é¸æ“‡åˆé©çš„ç”¢å“ï¼‰

## é¸è³¼è¦é»

### åŠ‘é‡å»ºè­°
ï¼ˆæ ¹æ“šç”¢å“è³‡æ–™çµ±è¨ˆï¼Œèªªæ˜å¸¸è¦‹åŠ‘é‡ç¯„åœï¼‰

### åŠ‘å‹æ¯”è¼ƒ
ï¼ˆæ¯”è¼ƒä¸åŒåŠ‘å‹çš„å„ªç¼ºé»ï¼šè† å›Šã€éŒ åŠ‘ã€æ¶²æ…‹ç­‰ï¼‰

### èªè­‰æ¨™æº–
ï¼ˆèªªæ˜å„åœ‹çš„èªè­‰æ¨™æº–å’Œæ„ç¾©ï¼‰

### åƒ¹æ ¼å¸¶åƒè€ƒ
ï¼ˆè‹¥æœ‰è³‡æ–™ï¼Œæä¾›åƒ¹æ ¼åƒè€ƒï¼‰

## å¸¸è¦‹å•é¡Œ FAQ

Q1: ï¼ˆæ ¹æ“šæ¶ˆè²»è€…å¯èƒ½çš„ç–‘å•ï¼Œæä¾› 5-10 å€‹å¸¸è¦‹å•é¡Œèˆ‡è§£ç­”ï¼‰
A1:

Q2:
A2:

...
```

æ³¨æ„ï¼š
1. æä¾›å¯¦ç”¨çš„é¸è³¼å»ºè­°
2. ä¿æŒå®¢è§€ï¼Œä¸æ¨è–¦ç‰¹å®šå“ç‰Œ
3. è‹¥è³‡æ–™ä¸è¶³ï¼Œè«‹æ¨™è¨»ã€Œå¾…è£œå……ã€
"""


def call_claude_api(prompt: str, max_tokens: int = 4000) -> Optional[str]:
    """å‘¼å« Claude API ç”¢ç”Ÿå…§å®¹"""
    if not HAS_ANTHROPIC:
        print("âš ï¸  anthropic å¥—ä»¶æœªå®‰è£ï¼Œç„¡æ³•å‘¼å« API")
        return None

    api_key = os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        print("âš ï¸  ANTHROPIC_API_KEY æœªè¨­å®š")
        return None

    try:
        client = anthropic.Anthropic(api_key=api_key)
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=max_tokens,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        return message.content[0].text
    except Exception as e:
        print(f"âŒ API å‘¼å«å¤±æ•—: {e}")
        return None


def generate_content(topic: dict, skip_web: bool = False, dry_run: bool = False, sample_limit: int = 0) -> dict:
    """ç”¢ç”Ÿä¸»é¡Œå…§å®¹

    Args:
        topic: ä¸»é¡Œå®šç¾©
        skip_web: æ˜¯å¦è·³éç¶²è·¯æœå°‹
        dry_run: æ˜¯å¦ç‚º dry run æ¨¡å¼
        sample_limit: å–æ¨£ä¸Šé™ï¼Œ0 è¡¨ç¤ºä¸é™åˆ¶
    """
    topic_id = topic["topic_id"]
    topic_name = topic["name"]["zh"]

    print(f"\nğŸ“ è™•ç†ä¸»é¡Œ: {topic_name} ({topic_id})")

    # æƒæç”¢å“
    print("  ğŸ“‚ æƒæç”¢å“è³‡æ–™...")
    products = scan_products(topic, sample_limit=sample_limit)
    print(f"  âœ… æ‰¾åˆ° {len(products)} ç­†åŒ¹é…ç”¢å“")

    if len(products) == 0:
        print("  âš ï¸  æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„ç”¢å“ï¼Œè·³é")
        return {"success": False, "reason": "no_products"}

    # å½™æ•´çµ±è¨ˆ
    summary = summarize_products(products)
    product_summary = format_product_summary(summary, topic)

    # ç¶²è·¯æœå°‹çµæœ
    if skip_web:
        web_results = "\n## ç¶²è·¯æœå°‹çµæœ\n\nï¼ˆå·²è·³éç¶²è·¯æœå°‹ï¼‰\n"
    else:
        web_results = format_web_results_placeholder(topic)

    # Dry run æ¨¡å¼
    if dry_run:
        print("\n" + "=" * 50)
        print("DRY RUN - ç”¢å“æ‘˜è¦")
        print("=" * 50)
        print(product_summary)
        print("\n" + "=" * 50)
        print("DRY RUN - å»ºè­°æœå°‹æŸ¥è©¢")
        print("=" * 50)
        print(web_results)
        return {"success": True, "dry_run": True}

    # ç”¢ç”Ÿ prompts
    index_prompt = generate_index_prompt(topic, product_summary, web_results)
    guide_prompt = generate_guide_prompt(topic, product_summary, web_results)

    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    output_dir = REPORTS_DIR / topic_id
    output_dir.mkdir(parents=True, exist_ok=True)

    results = {"success": True, "files": []}

    # ç”¢ç”Ÿ index.md
    print("  ğŸ¤– ç”¢ç”Ÿ index.md...")
    index_content = call_claude_api(index_prompt)
    if index_content:
        # åŠ å…¥ frontmatter
        frontmatter = f"""---
layout: default
title: {topic_name}
nav_order: 10
parent: å ±å‘Šç¸½è¦½
has_children: true
generated_at: "{datetime.now().isoformat()}"
product_count: {summary['count']}
---

"""
        index_path = output_dir / "index.md"
        index_path.write_text(frontmatter + index_content, encoding="utf-8")
        print(f"  âœ… å·²å¯«å…¥: {index_path.relative_to(PROJECT_ROOT)}")
        results["files"].append(str(index_path))
    else:
        print("  âš ï¸  index.md ç”¢ç”Ÿå¤±æ•—")

    # ç”¢ç”Ÿ guide.md
    print("  ğŸ¤– ç”¢ç”Ÿ guide.md...")
    guide_content = call_claude_api(guide_prompt)
    if guide_content:
        # åŠ å…¥ frontmatter
        frontmatter = f"""---
layout: default
title: é¸è³¼æŒ‡å—
nav_order: 2
parent: {topic_name}
grand_parent: å ±å‘Šç¸½è¦½
generated_at: "{datetime.now().isoformat()}"
---

"""
        guide_path = output_dir / "guide.md"
        guide_path.write_text(frontmatter + guide_content, encoding="utf-8")
        print(f"  âœ… å·²å¯«å…¥: {guide_path.relative_to(PROJECT_ROOT)}")
        results["files"].append(str(guide_path))
    else:
        print("  âš ï¸  guide.md ç”¢ç”Ÿå¤±æ•—")

    return results


def main():
    parser = argparse.ArgumentParser(description="AI ç”¢ç”Ÿä¸»é¡Œé¦–é å’Œé¸è³¼æŒ‡å—")
    parser.add_argument("--topic", help="æŒ‡å®šä¸»é¡Œ ID")
    parser.add_argument("--all", action="store_true", help="è™•ç†æ‰€æœ‰ä¸»é¡Œ")
    parser.add_argument("--skip-web", action="store_true", help="è·³éç¶²è·¯æœå°‹")
    parser.add_argument("--dry-run", action="store_true", help="åƒ…é¡¯ç¤ºæœƒç”¢ç”Ÿçš„å…§å®¹ï¼Œä¸å¯¦éš›åŸ·è¡Œ")
    parser.add_argument("--sample", type=int, default=0, help="å–æ¨£ä¸Šé™ï¼ˆç”¨æ–¼å¿«é€Ÿæ¸¬è©¦ï¼‰")
    args = parser.parse_args()

    print("=" * 50)
    print("ä¸»é¡Œå…§å®¹ç”¢ç”Ÿ")
    print("=" * 50)

    if not HAS_ANTHROPIC and not args.dry_run:
        print("âš ï¸  éœ€è¦å®‰è£ anthropic å¥—ä»¶: pip install anthropic")
        print("   æˆ–ä½¿ç”¨ --dry-run æ¨¡å¼æŸ¥çœ‹è³‡æ–™æ‘˜è¦")

    # è¼‰å…¥ä¸»é¡Œ
    if args.topic:
        topic = load_topic(args.topic)
        if not topic:
            print(f"âŒ æ‰¾ä¸åˆ°ä¸»é¡Œ: {args.topic}")
            return
        topics = [topic]
    elif args.all:
        topics = load_all_topics()
    else:
        parser.print_help()
        return

    print(f"ğŸ“‹ è¼‰å…¥ {len(topics)} å€‹ä¸»é¡Œ")
    if args.sample > 0:
        print(f"ğŸ“Š å–æ¨£æ¨¡å¼ï¼šæ¯ä¸»é¡Œæœ€å¤š {args.sample} ç­†ç”¢å“")

    for topic in topics:
        generate_content(
            topic,
            skip_web=args.skip_web,
            dry_run=args.dry_run,
            sample_limit=args.sample
        )

    print("\n" + "=" * 50)
    print("âœ… å®Œæˆ")
    print("=" * 50)


if __name__ == "__main__":
    main()
