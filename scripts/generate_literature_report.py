#!/usr/bin/env python3
"""æ–‡ç»è–ˆèƒå ±å‘Šç”¢å‡ºè…³æœ¬ â€” çµ±è¨ˆåˆ†æ PubMed æ–‡ç»è³‡æ–™"""
import json
import os
import sys
import glob
import argparse
import re
from datetime import datetime, timezone
from collections import defaultdict

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
PUBMED_DIR = os.path.join(BASE_DIR, "docs/Extractor/pubmed")
TOPICS_DIR = os.path.join(BASE_DIR, "core/Narrator/Modes/topic_tracking/topics")
OUTPUT_DIR = os.path.join(BASE_DIR, "docs/Narrator/literature_review")

# åŠŸæ•ˆåˆ†é¡ä¸­æ–‡åç¨±
CLAIM_CATEGORY_NAMES = {
    "anti_aging": "æŠ—è¡°è€",
    "cardiovascular": "å¿ƒè¡€ç®¡",
    "cognitive": "èªçŸ¥åŠŸèƒ½",
    "immune": "å…ç–«èª¿ç¯€",
    "metabolic": "ä»£è¬",
    "musculoskeletal": "è‚Œè‚‰éª¨éª¼",
    "sexual": "æ€§åŠŸèƒ½",
    "skin": "çš®è†š",
    "digestive": "æ¶ˆåŒ–",
    "energy": "æ´»åŠ›",
    "other": "å…¶ä»–",
}

# ç ”ç©¶é¡å‹ä¸­æ–‡åç¨±
STUDY_TYPE_NAMES = {
    "meta_analysis": "Meta-Analysis",
    "systematic_review": "Systematic Review",
    "rct": "RCT",
    "clinical_trial": "Clinical Trial",
    "observational": "Observational",
    "review": "Review",
    "case_report": "Case Report",
    "other": "Other",
}


def load_topic_config(topic_id: str) -> dict:
    """è¼‰å…¥ä¸»é¡Œè¨­å®šæª”"""
    import yaml
    topic_file = os.path.join(TOPICS_DIR, f"{topic_id}.yaml")
    if not os.path.exists(topic_file):
        return {"name": {"zh": topic_id, "en": topic_id}}

    with open(topic_file, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def parse_frontmatter(content: str) -> dict:
    """è§£æ Markdown frontmatter"""
    if not content.startswith("---"):
        return {}

    lines = content.split("\n")
    frontmatter = {}
    in_frontmatter = False
    fm_lines = []

    for line in lines:
        if line.strip() == "---":
            if in_frontmatter:
                break
            in_frontmatter = True
            continue
        if in_frontmatter:
            fm_lines.append(line)

    for line in fm_lines:
        if ":" in line:
            key, value = line.split(":", 1)
            key = key.strip()
            value = value.strip().strip('"').strip("'")
            # è™•ç† JSON é™£åˆ—
            if value.startswith("[") and value.endswith("]"):
                try:
                    frontmatter[key] = json.loads(value)
                except:
                    frontmatter[key] = value
            else:
                frontmatter[key] = value

    return frontmatter


def load_articles(topic_id: str) -> list:
    """è¼‰å…¥ç‰¹å®šä¸»é¡Œçš„æ‰€æœ‰æ–‡ç»"""
    topic_dir = os.path.join(PUBMED_DIR, topic_id)
    if not os.path.exists(topic_dir):
        return []

    articles = []
    for md_file in glob.glob(os.path.join(topic_dir, "*.md")):
        try:
            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read()

            # è·³é REVIEW_NEEDED
            if content.startswith("[REVIEW_NEEDED]"):
                continue

            fm = parse_frontmatter(content)
            if fm:
                # æå–æ‘˜è¦ï¼ˆç¬¬ä¸€å€‹ ## æ‘˜è¦ ä¹‹å¾Œçš„å…§å®¹ï¼‰
                abstract_match = re.search(r"## æ‘˜è¦\n(.+?)(?=\n## |$)", content, re.DOTALL)
                fm["abstract_text"] = abstract_match.group(1).strip() if abstract_match else ""
                articles.append(fm)
        except Exception as e:
            print(f"  è¼‰å…¥å¤±æ•—: {md_file}: {e}", file=sys.stderr)

    return articles


def calculate_statistics(articles: list) -> dict:
    """è¨ˆç®—æ–‡ç»çµ±è¨ˆè³‡æ–™"""
    stats = {
        "total": len(articles),
        "by_evidence_level": defaultdict(int),
        "by_study_type": defaultdict(int),
        "by_claim_category": defaultdict(int),
        "by_ingredient": defaultdict(int),
        "level_1_articles": [],
        "level_2_articles": [],
    }

    for article in articles:
        # è­‰æ“šç­‰ç´šçµ±è¨ˆ
        level = article.get("evidence_level", 5)
        try:
            level = int(level)
        except:
            level = 5
        stats["by_evidence_level"][level] += 1

        # ç ”ç©¶é¡å‹çµ±è¨ˆ
        study_type = article.get("study_type", "other")
        stats["by_study_type"][study_type] += 1

        # åŠŸæ•ˆåˆ†é¡çµ±è¨ˆ
        categories = article.get("claim_categories", [])
        if isinstance(categories, str):
            categories = [categories]
        for cat in categories:
            stats["by_claim_category"][cat] += 1

        # æˆåˆ†çµ±è¨ˆ
        ingredients = article.get("ingredients_mentioned", [])
        if isinstance(ingredients, str):
            ingredients = [ingredients]
        for ing in ingredients:
            stats["by_ingredient"][ing] += 1

        # æ”¶é›†é«˜è­‰æ“šç­‰ç´šæ–‡ç»
        if level == 1:
            stats["level_1_articles"].append(article)
        elif level == 2:
            stats["level_2_articles"].append(article)

    return stats


def generate_report(topic_id: str, period: str) -> str:
    """ç”¢ç”Ÿæ–‡ç»è–ˆèƒå ±å‘Š"""
    # è¼‰å…¥ä¸»é¡Œè¨­å®š
    config = load_topic_config(topic_id)
    topic_name = config.get("name", {}).get("zh", topic_id)

    # è¼‰å…¥æ–‡ç»
    articles = load_articles(topic_id)
    if not articles:
        return ""

    # è¨ˆç®—çµ±è¨ˆ
    stats = calculate_statistics(articles)
    now = datetime.now(timezone.utc).isoformat()

    # è§£ææœŸé–“
    year, month = period.split("-")

    # è¨ˆç®—ç™¾åˆ†æ¯”çš„è¼”åŠ©å‡½æ•¸
    def pct(count, total):
        return f"{count/total*100:.1f}%" if total > 0 else "0%"

    # æ§‹å»ºå ±å‘Š
    report = f"""---
topic: "{topic_id}"
period: "{period}"
generated_at: "{now}"
total_articles: {stats['total']}
---

# {topic_name}æ–‡ç»è–ˆèƒå ±å‘Š â€” {year} å¹´ {int(month)} æœˆ

## æ‘˜è¦

æœ¬æœˆå…±æ”¶éŒ„ {topic_name} ç›¸é—œæ–‡ç» {stats['total']} ç¯‡ï¼Œå…¶ä¸­ Level 1 è­‰æ“šï¼ˆMeta-Analysis/Systematic Reviewï¼‰{stats['by_evidence_level'].get(1, 0)} ç¯‡ï¼ŒRCT {stats['by_study_type'].get('rct', 0)} ç¯‡ã€‚

## è­‰æ“šç­‰ç´šåˆ†å¸ƒ

| è­‰æ“šç­‰ç´š | æ–‡ç»æ•¸ | ä½”æ¯” |
|----------|--------|------|
| Level 1 (Meta-Analysis/Systematic Review) | {stats['by_evidence_level'].get(1, 0)} | {pct(stats['by_evidence_level'].get(1, 0), stats['total'])} |
| Level 2 (RCT) | {stats['by_evidence_level'].get(2, 0)} | {pct(stats['by_evidence_level'].get(2, 0), stats['total'])} |
| Level 3 (Clinical Trial) | {stats['by_evidence_level'].get(3, 0)} | {pct(stats['by_evidence_level'].get(3, 0), stats['total'])} |
| Level 4 (Observational) | {stats['by_evidence_level'].get(4, 0)} | {pct(stats['by_evidence_level'].get(4, 0), stats['total'])} |
| Level 5 (Review/Case Report/Other) | {stats['by_evidence_level'].get(5, 0)} | {pct(stats['by_evidence_level'].get(5, 0), stats['total'])} |

## åŠŸæ•ˆåˆ†é¡çµ±è¨ˆ

| åŠŸæ•ˆåˆ†é¡ | ä¸­æ–‡ | æ–‡ç»æ•¸ | ä½”æ¯” |
|----------|------|--------|------|
"""

    # åŠŸæ•ˆåˆ†é¡çµ±è¨ˆï¼ˆæ’åºï¼‰
    sorted_categories = sorted(stats['by_claim_category'].items(), key=lambda x: -x[1])
    for cat, count in sorted_categories:
        cat_name = CLAIM_CATEGORY_NAMES.get(cat, cat)
        report += f"| {cat} | {cat_name} | {count} | {pct(count, stats['total'])} |\n"

    report += """
## æˆåˆ†æ­é…çµ±è¨ˆ

| æˆåˆ† | æ–‡ç»æ•¸ |
|------|--------|
"""

    # æˆåˆ†çµ±è¨ˆï¼ˆå–å‰ 10ï¼‰
    sorted_ingredients = sorted(stats['by_ingredient'].items(), key=lambda x: -x[1])[:10]
    for ing, count in sorted_ingredients:
        report += f"| {ing} | {count} |\n"

    report += """
## ç ”ç©¶é¡å‹åˆ†å¸ƒ

| ç ”ç©¶é¡å‹ | æ–‡ç»æ•¸ | ä½”æ¯” |
|----------|--------|------|
"""

    # ç ”ç©¶é¡å‹çµ±è¨ˆ
    for study_type in ["meta_analysis", "systematic_review", "rct", "clinical_trial",
                       "observational", "review", "case_report", "other"]:
        count = stats['by_study_type'].get(study_type, 0)
        type_name = STUDY_TYPE_NAMES.get(study_type, study_type)
        report += f"| {type_name} | {count} | {pct(count, stats['total'])} |\n"

    # Level 1 æ–‡ç»åˆ—è¡¨
    if stats['level_1_articles']:
        report += """
## è¿‘æœŸé‡è¦æ–‡ç»

### Level 1 è­‰æ“šï¼ˆMeta-Analysis / Systematic Reviewï¼‰

"""
        for i, article in enumerate(stats['level_1_articles'][:5], 1):
            title = article.get('title', 'Unknown')
            url = article.get('source_url', '')
            journal = article.get('journal', '')
            pub_date = article.get('pub_date', '')
            categories = article.get('claim_categories', [])
            if isinstance(categories, list):
                categories = ", ".join(categories)

            report += f"{i}. **[{title}]({url})** â€” {journal}, {pub_date}\n"
            report += f"   - åŠŸæ•ˆåˆ†é¡ï¼š{categories}\n\n"

    # Level 2 æ–‡ç»åˆ—è¡¨
    if stats['level_2_articles']:
        report += """
### Level 2 è­‰æ“šï¼ˆRCTï¼‰

"""
        for i, article in enumerate(stats['level_2_articles'][:5], 1):
            title = article.get('title', 'Unknown')
            url = article.get('source_url', '')
            journal = article.get('journal', '')
            pub_date = article.get('pub_date', '')
            categories = article.get('claim_categories', [])
            if isinstance(categories, list):
                categories = ", ".join(categories)

            report += f"{i}. **[{title}]({url})** â€” {journal}, {pub_date}\n"
            report += f"   - åŠŸæ•ˆåˆ†é¡ï¼š{categories}\n\n"

    return report


def list_topics() -> list:
    """åˆ—å‡ºæœ‰ pubmed æ–‡ç»çš„ä¸»é¡Œ"""
    topics = []
    if not os.path.exists(PUBMED_DIR):
        return topics

    for item in os.listdir(PUBMED_DIR):
        item_path = os.path.join(PUBMED_DIR, item)
        if os.path.isdir(item_path) and item != "raw":
            # ç¢ºèªç›®éŒ„ä¸‹æœ‰ .md æª”æ¡ˆ
            if glob.glob(os.path.join(item_path, "*.md")):
                topics.append(item)

    return topics


def main():
    parser = argparse.ArgumentParser(description="æ–‡ç»è–ˆèƒå ±å‘Šç”¢å‡º")
    parser.add_argument("--topic", help="æŒ‡å®šä¸»é¡Œ ID")
    parser.add_argument("--all", action="store_true", help="ç”¢å‡ºæ‰€æœ‰ä¸»é¡Œå ±å‘Š")
    parser.add_argument("--period", help="å ±å‘ŠæœŸé–“ (YYYY-MM)ï¼Œé è¨­ç‚ºæœ¬æœˆ")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºå¯ç”¨ä¸»é¡Œ")
    args = parser.parse_args()

    if args.list:
        topics = list_topics()
        print("æœ‰æ–‡ç»è³‡æ–™çš„ä¸»é¡Œ:")
        for t in topics:
            print(f"  - {t}")
        return

    # æ±ºå®šæœŸé–“
    if args.period:
        period = args.period
    else:
        period = datetime.now().strftime("%Y-%m")

    # æ±ºå®šä¸»é¡Œ
    if args.all:
        topics = list_topics()
    elif args.topic:
        topics = [args.topic]
    else:
        print("è«‹æŒ‡å®š --topic æˆ– --all", file=sys.stderr)
        sys.exit(1)

    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print("ğŸ“Š æ–‡ç»è–ˆèƒå ±å‘Šç”¢å‡º")
    print(f"   ä¸»é¡Œæ•¸ï¼š{len(topics)}")
    print(f"   å ±å‘ŠæœŸé–“ï¼š{period}")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

    for topic_id in topics:
        print(f"\nğŸ“– è™•ç†ä¸»é¡Œ: {topic_id}")

        report = generate_report(topic_id, period)
        if not report:
            print("  ç„¡æ–‡ç»è³‡æ–™ï¼Œè·³é")
            continue

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        topic_output_dir = os.path.join(OUTPUT_DIR, topic_id)
        os.makedirs(topic_output_dir, exist_ok=True)

        # å¯«å…¥å ±å‘Š
        output_file = os.path.join(topic_output_dir, f"{period}.md")
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(report)

        print(f"  âœ… ç”¢å‡ºå ±å‘Šï¼š{output_file}")

    print("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print("âœ… å ±å‘Šç”¢å‡ºå®Œæˆ")


if __name__ == "__main__":
    main()
