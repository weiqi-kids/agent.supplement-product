#!/usr/bin/env python3
"""
Generate topic tracking reports for February 2026
"""

import os
import re
import yaml
from pathlib import Path
from datetime import datetime
from collections import defaultdict, Counter
from typing import Dict, List, Set, Tuple

# Base paths
BASE_DIR = Path("/Users/lightman/weiqi.kids/agent.supplement-product")
EXTRACTOR_DIR = BASE_DIR / "docs" / "Extractor"
TOPICS_DIR = BASE_DIR / "core" / "Narrator" / "Modes" / "topic_tracking" / "topics"
OUTPUT_DIR = BASE_DIR / "docs" / "Narrator" / "topic_tracking"

# Layer mapping
LAYERS = {
    "us_dsld": "ğŸ‡ºğŸ‡¸ ç¾åœ‹",
    "ca_lnhpd": "ğŸ‡¨ğŸ‡¦ åŠ æ‹¿å¤§",
    "kr_hff": "ğŸ‡°ğŸ‡· éŸ“åœ‹",
    "jp_fnfc": "ğŸ‡¯ğŸ‡µ æ—¥æœ¬ (FNFC)",
    "jp_foshu": "ğŸ‡¯ğŸ‡µ æ—¥æœ¬ (FOSHU)"
}

def load_topic(topic_file: Path) -> Dict:
    """Load topic definition from YAML file"""
    with open(topic_file, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def extract_field(content: str, field_name: str) -> str:
    """Extract field value from markdown content"""
    pattern = rf'^##\s+{re.escape(field_name)}\s*\n+(.*?)(?=\n##|\Z)'
    match = re.search(pattern, content, re.MULTILINE | re.DOTALL)
    if match:
        return match.group(1).strip()
    return ""

def extract_list_items(content: str, section: str) -> List[str]:
    """Extract list items from a section"""
    section_content = extract_field(content, section)
    if not section_content:
        return []

    items = []
    for line in section_content.split('\n'):
        line = line.strip()
        if line.startswith('- '):
            items.append(line[2:].strip())
        elif line.startswith('* '):
            items.append(line[2:].strip())
    return items

def matches_keyword(text: str, keywords: List[str], case_sensitive: bool = False) -> Tuple[bool, List[str]]:
    """Check if text matches any keyword"""
    if not text:
        return False, []

    matched = []
    search_text = text if case_sensitive else text.lower()

    for keyword in keywords:
        search_keyword = keyword if case_sensitive else keyword.lower()
        if search_keyword in search_text:
            matched.append(keyword)

    return len(matched) > 0, matched

def process_product(file_path: Path, topic: Dict) -> Tuple[bool, Dict]:
    """Check if product matches topic and extract data"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # Skip REVIEW_NEEDED products
        if '[REVIEW_NEEDED]' in content.split('\n')[0]:
            return False, {}

        # Try to extract from frontmatter first
        frontmatter = {}
        if content.startswith('---'):
            try:
                parts = content.split('---', 2)
                if len(parts) >= 3:
                    frontmatter = yaml.safe_load(parts[1])
            except:
                pass

        # Extract metadata from frontmatter or markdown sections
        product_name = frontmatter.get('product_name') or extract_field(content, 'ç”¢å“åç¨±') or extract_field(content, 'ç”¢å“å') or extract_field(content, 'å“å')
        brand = frontmatter.get('brand') or extract_field(content, 'å“ç‰Œ') or extract_field(content, 'è£½é€ å•†') or extract_field(content, 'ç”³è«‹è€…')
        product_form = frontmatter.get('product_form') or extract_field(content, 'åŠ‘å‹')
        date_entered = frontmatter.get('date_entered') or extract_field(content, 'ç™»éŒ„æ—¥æœŸ') or extract_field(content, 'è¨±å¯æ—¥æœŸ') or extract_field(content, 'å—ç†æ—¥')

        # Extract ingredients
        ingredients_str = extract_field(content, 'æˆåˆ†') or extract_field(content, 'æ©Ÿèƒ½æ€§æˆåˆ†') or extract_field(content, 'é—œèˆ‡è¡¨ç¤ºã®ç§‘å­¦çš„æ ¹æ‹ ç­‰ã«é–¢ã™ã‚‹åŸºæœ¬æƒ…å ±')
        ingredients = extract_list_items(content, 'æˆåˆ†') or extract_list_items(content, 'æ©Ÿèƒ½æ€§æˆåˆ†')

        # Check exact match (ingredients)
        exact_match, exact_keywords = matches_keyword(ingredients_str, topic['keywords'].get('exact', []))

        # Check fuzzy match (product name)
        fuzzy_match, fuzzy_keywords = matches_keyword(product_name, topic['keywords'].get('fuzzy', []))

        if not (exact_match or fuzzy_match):
            return False, {}

        return True, {
            'file': file_path.name,
            'product_name': product_name,
            'brand': brand,
            'product_form': product_form,
            'date_entered': date_entered,
            'ingredients': ingredients,
            'matched_exact': exact_keywords,
            'matched_fuzzy': fuzzy_keywords
        }

    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return False, {}

def scan_layer(layer: str, topic: Dict) -> List[Dict]:
    """Scan a layer for products matching the topic"""
    layer_dir = EXTRACTOR_DIR / layer
    if not layer_dir.exists():
        return []

    matched_products = []
    category_filters = topic.get('category_filter', [])

    # If no filter, scan all categories
    if not category_filters:
        category_filters = [d.name for d in layer_dir.iterdir() if d.is_dir() and d.name != 'raw']

    for category in category_filters:
        category_dir = layer_dir / category
        if not category_dir.exists():
            continue

        for md_file in category_dir.glob('*.md'):
            is_match, data = process_product(md_file, topic)
            if is_match:
                data['layer'] = layer
                data['category'] = category
                matched_products.append(data)

    return matched_products

def generate_report(topic_id: str, topic: Dict, products_by_layer: Dict[str, List[Dict]]) -> str:
    """Generate markdown report for a topic"""

    # Calculate total
    total_products = sum(len(prods) for prods in products_by_layer.values())

    if total_products == 0:
        return None

    # Analyze data
    all_products = []
    for prods in products_by_layer.values():
        all_products.extend(prods)

    # Brand analysis
    brand_counter = Counter()
    for prod in all_products:
        if prod['brand']:
            brand_counter[prod['brand']] += 1

    # Product form analysis
    form_counter = Counter()
    for prod in all_products:
        if prod['product_form']:
            form_counter[prod['product_form']] += 1

    # Market distribution
    market_stats = []
    for layer, prods in products_by_layer.items():
        if prods:
            brands = [p['brand'] for p in prods if p['brand']]
            top_brands = Counter(brands).most_common(3)
            market_stats.append({
                'layer': layer,
                'count': len(prods),
                'brands': [b[0] for b in top_brands]
            })

    # Generate report
    report_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    report = f"""---
topic: {topic_id}
period: "2026-02"
generated_at: "{report_date}"
---

# {topic['name']['zh']}å¸‚å ´å ±å‘Š â€” 2026 å¹´ 2 æœˆ

## æ‘˜è¦

æœ¬å ±å‘Šè¿½è¹¤å…¨çƒäº”å¤§å¸‚å ´ï¼ˆç¾åœ‹ã€åŠ æ‹¿å¤§ã€éŸ“åœ‹ã€æ—¥æœ¬ï¼‰çš„{topic['name']['zh']}ç›¸é—œä¿å¥é£Ÿå“ã€‚æˆªè‡³ 2026 å¹´ 2 æœˆï¼Œå…±è­˜åˆ¥å‡º {total_products} ç­†ç¬¦åˆä¸»é¡Œçš„ç”¢å“è³‡æ–™ï¼Œæ¶µè“‹ {len([l for l, p in products_by_layer.items() if p])} å€‹å¸‚å ´ã€‚

{topic['name']['zh']}ç”¢å“åœ¨å„å¸‚å ´å‘ˆç¾ä¸åŒç‰¹è‰²ï¼šç¾åœ‹èˆ‡åŠ æ‹¿å¤§å¸‚å ´ç”¢å“ç¨®é¡è±å¯Œï¼ŒéŸ“åœ‹èˆ‡æ—¥æœ¬å¸‚å ´å‰‡ä»¥æ©Ÿèƒ½æ€§æ˜ç¢ºçš„ç”¢å“ç‚ºä¸»ã€‚

## å„åœ‹ç”¢å“çµ±è¨ˆ

| å¸‚å ´ | ç”¢å“æ•¸ | ä¸»è¦å“ç‰Œ |
|------|--------|----------|
"""

    for stat in sorted(market_stats, key=lambda x: x['count'], reverse=True):
        brands_str = "ã€".join(stat['brands'][:3]) if stat['brands'] else "â€”"
        report += f"| {LAYERS[stat['layer']]} | {stat['count']} | {brands_str} |\n"

    report += f"\n**çµ±è¨ˆèªªæ˜**ï¼šæœ¬çµ±è¨ˆæ’é™¤æ¨™è¨˜ç‚º `[REVIEW_NEEDED]` çš„ç”¢å“ã€‚\n\n"

    # Top brands
    if brand_counter:
        report += "## ç†±é–€å“ç‰Œ/è£½é€ å•†\n\n"
        report += "| æ’å | å“ç‰Œ/è£½é€ å•† | ç”¢å“æ•¸ | ä¸»è¦å¸‚å ´ |\n"
        report += "|------|-------------|--------|----------|\n"

        for rank, (brand, count) in enumerate(brand_counter.most_common(10), 1):
            # Find markets for this brand
            markets = set()
            for prod in all_products:
                if prod['brand'] == brand:
                    markets.add(prod['layer'])

            market_flags = " ".join([LAYERS[m].split()[0] for m in sorted(markets)])
            report += f"| {rank} | {brand} | {count} | {market_flags} |\n"

        report += "\n"

    # Product forms
    if form_counter:
        report += "## åŠ‘å‹åˆ†å¸ƒ\n\n"
        report += "| åŠ‘å‹ | ç”¢å“æ•¸ | ä½”æ¯” |\n"
        report += "|------|--------|------|\n"

        for form, count in form_counter.most_common(10):
            percentage = (count / total_products) * 100
            report += f"| {form} | {count} | {percentage:.1f}% |\n"

        report += "\n"

    # Recent products (if date_entered available)
    recent_products = [p for p in all_products if p.get('date_entered')]
    if recent_products:
        # Try to parse dates and sort
        dated_products = []
        for p in recent_products:
            date_str = p['date_entered']
            # Try to extract year-month
            match = re.search(r'(202[0-9])[/-]?([0-1][0-9])', date_str)
            if match:
                year, month = match.groups()
                dated_products.append((f"{year}-{month}", p))

        if dated_products:
            dated_products.sort(reverse=True, key=lambda x: x[0])

            # Filter for recent entries (2025-12 onwards)
            new_products = [(d, p) for d, p in dated_products if d >= "2025-12"]

            if new_products:
                report += "## æ–°å“ä¸Šå¸‚\n\n"
                report += "ä»¥ä¸‹ç‚ºè¿‘æœŸæ–°å¢çš„ç”¢å“ç™»éŒ„ï¼š\n\n"

                for date, prod in new_products[:10]:
                    market = LAYERS[prod['layer']].split()[0]
                    report += f"- **{prod['product_name']}**ï¼ˆ{prod['brand'] or 'æœªæ¨™ç¤º'}ï¼‰â€” {market} {date}\n"

                report += "\n"

    # Trend observations
    report += "## è¶¨å‹¢è§€å¯Ÿ\n\n"

    # Analyze by market
    observations = []

    for layer, prods in products_by_layer.items():
        if not prods:
            continue

        market_name = LAYERS[layer]

        # Dominant forms
        forms = [p['product_form'] for p in prods if p['product_form']]
        if forms:
            top_form = Counter(forms).most_common(1)[0]
            if top_form[1] >= len(prods) * 0.3:  # If >30% are same form
                observations.append(f"{market_name}å¸‚å ´ä»¥ **{top_form[0]}** ç‚ºä¸»è¦åŠ‘å‹ï¼ˆ{top_form[1]} ç­†ï¼Œ{top_form[1]/len(prods)*100:.1f}%ï¼‰")

    if observations:
        for obs in observations:
            report += f"- {obs}\n"
    else:
        report += f"- {topic['name']['zh']}ç”¢å“åœ¨å„å¸‚å ´å‘ˆç¾å¤šæ¨£åŒ–çš„åŠ‘å‹èˆ‡é…æ–¹\n"
        report += f"- ç”¢å“ç¸½æ•¸é” {total_products} ç­†ï¼Œé¡¯ç¤ºå¸‚å ´å°æ­¤é¡ç”¢å“æœ‰ç©©å®šéœ€æ±‚\n"

    # Matching keywords analysis
    exact_matches = sum(1 for p in all_products if p.get('matched_exact'))
    fuzzy_matches = sum(1 for p in all_products if p.get('matched_fuzzy') and not p.get('matched_exact'))

    report += f"\n**åŒ¹é…èªªæ˜**ï¼š{exact_matches} ç­†ç”¢å“é€éæˆåˆ†ç²¾ç¢ºåŒ¹é…è­˜åˆ¥ï¼Œ{fuzzy_matches} ç­†é€éç”¢å“åç¨±æ¨¡ç³ŠåŒ¹é…è­˜åˆ¥ã€‚\n\n"

    # Footer
    report += "---\n\n"
    report += "*æœ¬å ±å‘Šç”± AI è‡ªå‹•ç”¢å‡ºï¼Œè³‡æ–™ä¾†æºç‚ºå„åœ‹ä¿å¥é£Ÿå“å®˜æ–¹è³‡æ–™åº«ã€‚å ±å‘Šå…§å®¹åƒ…ä¾›å¸‚å ´ç ”ç©¶åƒè€ƒï¼Œä¸æ§‹æˆç”¢å“æ¨è–¦æˆ–å¥åº·å»ºè­°ã€‚*\n"

    return report

def main():
    """Main execution"""
    print("=== ä¸»é¡Œè¿½è¹¤å ±å‘Šç”¢å‡º â€” 2026 å¹´ 2 æœˆ ===\n")

    # Load topics
    topic_files = list(TOPICS_DIR.glob("*.yaml"))
    print(f"ç™¼ç¾ {len(topic_files)} å€‹è¿½è¹¤ä¸»é¡Œ\n")

    results = []

    for topic_file in topic_files:
        topic = load_topic(topic_file)
        topic_id = topic['topic_id']

        print(f"è™•ç†ä¸»é¡Œ: {topic['name']['zh']} ({topic_id})")
        print(f"  ç²¾ç¢ºé—œéµè©: {len(topic['keywords'].get('exact', []))} å€‹")
        print(f"  æ¨¡ç³Šé—œéµè©: {len(topic['keywords'].get('fuzzy', []))} å€‹")
        print(f"  åˆ†é¡ç¯©é¸: {', '.join(topic.get('category_filter', ['å…¨éƒ¨']))}")

        # Scan each layer
        products_by_layer = {}
        total_matched = 0

        for layer in LAYERS.keys():
            print(f"  æƒæ {LAYERS[layer]}...", end=" ")
            matched = scan_layer(layer, topic)
            products_by_layer[layer] = matched
            print(f"{len(matched)} ç­†")
            total_matched += len(matched)

        print(f"  ç¸½è¨ˆåŒ¹é…: {total_matched} ç­†ç”¢å“\n")

        if total_matched > 0:
            # Generate report
            report = generate_report(topic_id, topic, products_by_layer)

            if report:
                # Write to file
                output_dir = OUTPUT_DIR / topic_id
                output_dir.mkdir(parents=True, exist_ok=True)
                output_file = output_dir / "2026-02.md"

                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(report)

                print(f"  âœ… å ±å‘Šå·²ç”¢å‡º: {output_file}\n")

                results.append({
                    'topic': topic['name']['zh'],
                    'topic_id': topic_id,
                    'count': total_matched,
                    'file': str(output_file)
                })
            else:
                print(f"  âš ï¸  ç„¡æœ‰æ•ˆè³‡æ–™ï¼Œè·³éå ±å‘Šç”¢å‡º\n")
        else:
            print(f"  âš ï¸  æœªæ‰¾åˆ°åŒ¹é…ç”¢å“ï¼Œè·³éå ±å‘Šç”¢å‡º\n")

    # Summary
    print("=" * 60)
    print("åŸ·è¡Œå®Œæˆ\n")
    print("## ç”¢å‡ºå ±å‘Šæ‘˜è¦\n")

    if results:
        for r in results:
            print(f"- **{r['topic']}** ({r['topic_id']}): {r['count']} ç­†ç”¢å“")
            print(f"  æª”æ¡ˆ: {r['file']}")
        print()
    else:
        print("ç„¡å ±å‘Šç”¢å‡ºï¼ˆæœªæ‰¾åˆ°åŒ¹é…ç”¢å“ï¼‰\n")

    return results

if __name__ == "__main__":
    main()
